import os
import json
from tqdm import tqdm
from PIL import Image
import torch
from transformers import AutoTokenizer, AutoImageProcessor, AutoModelForSeq2SeqLM

# ===== æ¨¡å‹é…ç½® =====
os.environ["CUDA_VISIBLE_DEVICES"] = "7"
model_id = "ahmed-masry/ChartInstruct-FlanT5-XL"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

# ===== å¤šæ–‡ä»¶è·¯å¾„é…ç½® =====
input_jsons = [
    "/data/jguo376/project/dataset/chartsumm/test_k.json",
    "/data/jguo376/project/dataset/chartsumm/test_s.json"
]
output_jsons = [
    "/data/jguo376/project/model/chartInstruction/test_k_output.json",
    "/data/jguo376/project/model/chartInstruction/test_s_output.json"
]
image_root = "/data/jguo376/project/dataset/chartsumm/chart_images"

# ===== åŠ è½½æ¨¡å‹ =====
print("ğŸš€ åŠ è½½ ChartInstruct-FlanT5-XL æ¨¡å‹ä¸­...")
model = AutoModelForSeq2SeqLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device.type == "cuda" else torch.float32,
    trust_remote_code=True
).to(device)
tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)
image_processor = AutoImageProcessor.from_pretrained(model_id)

# ===== æ¨ç†å‡½æ•° =====
def infer_chartinstruct(image_path, input_question="Please describe the chart."):
    image = Image.open(image_path).convert("RGB")
    prompt = f"<image>\n Question: {input_question} Answer: "

    text_inputs = tokenizer(
        prompt,
        return_tensors="pt",
        padding="max_length",
        truncation=True,
        max_length=512
    )
    pixel_values = image_processor(images=image, return_tensors="pt")["pixel_values"].to(
        device, dtype=torch.float16 if device.type == "cuda" else torch.float32
    )
    print(f"[INFO] pixel_values.shape for {os.path.basename(image_path)}: {pixel_values.shape}")

    inputs = {
        "input_ids": text_inputs["input_ids"].to(device),
        "attention_mask": text_inputs["attention_mask"].to(device),
        "pixel_values": pixel_values
    }

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            num_beams=4,
            max_new_tokens=512,
            early_stopping=True
        )

    output_text = tokenizer.batch_decode(
        outputs,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=True
    )[0]
    return output_text

# ===== æ‰¹é‡å¤„ç†æ¯ä¸ªæ–‡ä»¶ =====
for input_path, output_path in zip(input_jsons, output_jsons):
    print(f"\nğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶: {input_path}")
    
    with open(input_path, "r", encoding="utf-8") as f:
        data_list = json.load(f)

    # ==== åŠ è½½å·²å®Œæˆé¡¹ï¼ˆç”¨äºæ–­ç‚¹ç»­è·‘ï¼‰ ====
    done_images = set()
    results = []
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            results = json.load(f)
            done_images = {item["image"] for item in results}
        print(f"ğŸ”„ å·²æ£€æµ‹åˆ° {len(done_images)} æ¡ç»“æœï¼Œå°†è·³è¿‡å·²å®Œæˆçš„å›¾åƒã€‚")

    # ==== å¼€å§‹å¤„ç† ====
    for idx, item in enumerate(tqdm(data_list, desc=f"Generating captions for {os.path.basename(input_path)}")):
        image_name = item.get("image") or item.get("img")
        if image_name in done_images:
            continue

        image_path = os.path.join(image_root, image_name)
        if not os.path.exists(image_path):
            caption = f"[ERROR] Image not found: {image_path}"
        else:
            try:
                caption = infer_chartinstruct(image_path)
            except Exception as e:
                caption = f"[ERROR] {str(e)}"

        result_item = {
            "image": image_name,
            "generated_caption": caption
        }
        results.append(result_item)

        print(f"[âœ“] {image_name}\n    â†’ {caption}\n")

        # æ¯å¤„ç†10æ¡ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
        if len(results) % 10 == 0:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, ensure_ascii=False)

    # æœ€ç»ˆä¿å­˜å®Œæ•´ç»“æœ
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"âœ… æœ€ç»ˆç»“æœä¿å­˜åˆ°: {output_path}")
