import torch
from PIL import Image
from transformers import AutoTokenizer, AutoImageProcessor, AutoModelForSeq2SeqLM
import os

# ===== æ¨¡å‹é…ç½® =====
os.environ["CUDA_VISIBLE_DEVICES"] = "7"

# ========= é…ç½®è·¯å¾„ =========
image_path = "/data/jguo376/project/dataset/ChartX_dataset/ChartX/bar_chart/png/bar_1.png"
input_question = "Please describe the chart."

# ========= è®¾å¤‡é€‰æ‹© =========
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

# ========= åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ï¼ˆæ‰‹åŠ¨æ–¹å¼ï¼‰=========
model_id = "ahmed-masry/ChartInstruct-FlanT5-XL"

model = AutoModelForSeq2SeqLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device.type == "cuda" else torch.float32,
    trust_remote_code=True
).to(device)

tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)
image_processor = AutoImageProcessor.from_pretrained(model_id)

# ========= è¯»å–å›¾ç‰‡å’Œæ„å»ºè¾“å…¥ =========
image = Image.open(image_path).convert("RGB")
input_prompt = f"<image>\n Question: {input_question} Answer: "

# æ–‡æœ¬ç¼–ç 
text_inputs = tokenizer(
    input_prompt,
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=512
)

# å›¾åƒç¼–ç å¹¶è½¬ä¸ºæŒ‡å®šè®¾å¤‡
pixel_values = image_processor(images=image, return_tensors="pt")["pixel_values"].to(
    device, dtype=torch.float16 if device.type == "cuda" else torch.float32
)

# åˆå¹¶ä¸ºæ¨¡å‹è¾“å…¥
inputs = {
    "input_ids": text_inputs["input_ids"].to(device),
    "attention_mask": text_inputs["attention_mask"].to(device),
    "pixel_values": pixel_values
}

# ========= æ¨ç†å¹¶ç”Ÿæˆç­”æ¡ˆ =========
with torch.no_grad():
    generate_ids = model.generate(
        **inputs,
        num_beams=4,
        max_new_tokens=512,
        early_stopping=True
    )

# ========= è§£ç è¾“å‡º =========
output = tokenizer.batch_decode(
    generate_ids,
    skip_special_tokens=True,
    clean_up_tokenization_spaces=True
)[0]

# ========= æ‰“å°ç»“æœ =========
print("\nğŸ“Š è¾“å…¥é—®é¢˜:", input_question)
print("ğŸ¤– æ¨¡å‹å›ç­”:", output)
