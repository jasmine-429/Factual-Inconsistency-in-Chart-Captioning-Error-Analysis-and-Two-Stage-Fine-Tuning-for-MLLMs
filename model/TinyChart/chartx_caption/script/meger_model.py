import sys
sys.path.append("/data/jguo376/project/model/TinyChart")

import torch
import json
import os
import pandas as pd
import numpy as np
from PIL import Image
from tqdm import tqdm
from scipy.stats import kendalltau
from tinychart.model.builder import load_pretrained_model
from tinychart.mm_utils import get_model_name_from_path
from tinychart.eval.run_tiny_chart import inference_model
from peft import PeftModel

# ======= é…ç½®è·¯å¾„ =======
model_path = "/data/jguo376/pretrained_models/TinyChart-3B-768"
lora_paths = [
    "/data/jguo376/project/model/TinyChart/checkpoints/chartx_caption/checkpoint-800",
    "/data/jguo376/project/model/TinyChart/checkpoints/chart_entail/checkpoint-700"
]
save_path = "/data/jguo376/project/model/TinyChart/merged_models/chart_entail_caption_merged"

device = "cuda:0"

# ======= åŠ è½½ base æ¨¡å‹ =======
tokenizer, model, image_processor, context_len = load_pretrained_model(
    model_path=model_path,
    model_base=None,
    model_name=get_model_name_from_path(model_path),
    device=device
)
model = model.half()

# ======= ä¾æ¬¡åˆå¹¶å¤šä¸ª LoRA =======
for i, lora_path in enumerate(lora_paths):
    print(f"ğŸ”„ Loading & merging LoRA {i+1}: {lora_path}")
    model = PeftModel.from_pretrained(model, lora_path)
    model = model.merge_and_unload()  # åˆå¹¶åè¿”å›çš„æ˜¯åŸå§‹æ¨¡å‹
    model = model.half()  # å†æ¬¡åŠç²¾åº¦è½¬æ¢ä»¥é˜²æ­¢ç±»å‹å†²çª

print("âœ… æ‰€æœ‰ LoRA åˆå¹¶å®Œæˆï¼")

# ======= ä¿å­˜åˆå¹¶åçš„æ¨¡å‹æƒé‡ =======
save_path = os.path.abspath(save_path)
os.makedirs(save_path, exist_ok=True)
print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°ï¼š{save_path}")
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)
print("ğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆï¼ä½ ç°åœ¨å¯ä»¥åƒæ™®é€š TinyChart æ¨¡å‹ä¸€æ ·åŠ è½½å®ƒäº†ã€‚")