import json
import random
from collections import defaultdict

# ===== æ–‡ä»¶è·¯å¾„é…ç½® =====
pos_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/test_samples_id.json"
value_error_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/error_data/value_error_augmented.json"
label_error_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/error_data/label_error_augmented.json"
trend_error_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/error_data/trend_errors.json"
ooc_error_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/error_data/ooc_error_augmented.json"
nonsense_error_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/error_data/nonsence_error_augmented.json"
output_file = "/data/jguo376/project/dataset/test_dataset/ChartX/test_data/dataset/test_balanced_mixed.json"

# ===== é”™è¯¯ç±»å‹æ¯”ä¾‹é…ç½® =====
error_ratios = {
    "value_error": 0.25,
    "label_error": 0.25,
    "trend_error": 0.15,
    "magnitude_error": 0.15,
    "ooc_error": 0.10,
    "nonsense_error": 0.10,
}

# ===== åŠ è½½æ­£æ ·æœ¬ =====
with open(pos_file) as f:
    pos_data = json.load(f)
random.shuffle(pos_data)
num_pos = 300  # âœ… å›ºå®šå– 20000 ä¸ªæ­£æ ·æœ¬
pos_data = pos_data[:num_pos]

# ===== è®¡ç®—è´Ÿæ ·æœ¬ç›®æ ‡æ•° =====
neg_target = int(num_pos * 1.2)
print(f"âœ… æ­£æ ·æœ¬æ•°é‡: {num_pos}")
print(f"ğŸ¯ ç›®æ ‡è´Ÿæ ·æœ¬æ•°é‡: {neg_target}")

# ===== åŠ è½½è´Ÿæ ·æœ¬æ±  =====
with open(value_error_file) as f:
    value_data = json.load(f)
with open(label_error_file) as f:
    label_data = json.load(f)
with open(trend_error_file) as f:
    trend_data = json.load(f)
with open(ooc_error_file) as f:
    ooc_data = json.load(f)
with open(nonsense_error_file) as f:
    nonsense_data = json.load(f)

# trend_error å’Œ magnitude_error åˆ†å¼€
error_pool = defaultdict(list)
for item in value_data:
    error_pool["value_error"].append(item)
for item in label_data:
    error_pool["label_error"].append(item)
for item in trend_data:
    if item["error"] == "trend_error":
        error_pool["trend_error"].append(item)
    elif item["error"] == "magnitude_error":
        error_pool["magnitude_error"].append(item)
for item in ooc_data:
    error_pool["ooc_error"].append(item)
for item in nonsense_data:
    error_pool["nonsense_error"].append(item)

# ===== åˆ†é…è´Ÿæ ·æœ¬ï¼ˆä¸è¶³å°±è¡¥ï¼‰=====
neg_selected = []
actual_counts = {}
deficit = 0

# é˜¶æ®µ1ï¼šå°è¯•æŒ‰é…é¢é‡‡æ ·
for err_type, ratio in error_ratios.items():
    target_n = int(neg_target * ratio)
    pool = error_pool.get(err_type, [])
    random.shuffle(pool)
    if len(pool) >= target_n:
        selected = pool[:target_n]
    else:
        selected = pool
        deficit += (target_n - len(pool))
    actual_counts[err_type] = len(selected)
    neg_selected.extend(selected)

# é˜¶æ®µ2ï¼šè¡¥è¶³ä¸è¶³éƒ¨åˆ†ï¼ˆä»æœ‰å‰©ä½™çš„ç±»å‹ä¸­å¡«ï¼‰
# ç»Ÿè®¡å“ªäº›è¿˜æœ‰å¯Œä½™
replenish_types = [k for k in error_ratios if len(error_pool[k]) > actual_counts.get(k, 0)]
remaining_total = sum([error_ratios[k] for k in replenish_types])
alloc = {k: int(deficit * (error_ratios[k] / remaining_total)) for k in replenish_types}

for err_type, extra_n in alloc.items():
    already_used = actual_counts[err_type]
    pool = error_pool[err_type][already_used:]
    random.shuffle(pool)
    supplement = pool[:extra_n]
    actual_counts[err_type] += len(supplement)
    neg_selected.extend(supplement)

# ===== åˆå¹¶å¹¶ä¿å­˜ =====
final_data = pos_data + neg_selected
random.shuffle(final_data)

with open(output_file, "w") as f:
    json.dump(final_data, f, indent=2)

# ===== æ‰“å°ç»Ÿè®¡ =====
print(f"\nâœ… æœ€ç»ˆæ ·æœ¬æ€»æ•°: {len(final_data)}")
print(f"ğŸ“Š å„ç±»è´Ÿæ ·æœ¬å®é™…æ•°é‡:")
for k, v in actual_counts.items():
    print(f"  {k:<16} : {v}")
